export const interviewProjects = [
  {
    slug: 'kafka-audit-logging',
    title: 'Kafka Audit Logging System',
    subtitle: 'Three-tier architecture: Library \u2192 Kafka \u2192 GCS \u2192 BigQuery',
    company: 'Walmart Luminate',
    role: 'Designed & built from scratch',
    // Single master document — will be split by H2 headings at runtime
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Events/day', value: '2M+' },
      { label: 'P99 impact', value: '<5ms' },
      { label: 'Cost savings', value: '99%' },
      { label: 'Teams adopted', value: '3+' },
      { label: 'Retention', value: '7 years' },
      { label: 'Integration', value: '1 day' },
    ],
    pitches: {
      '30s': `When Walmart decommissioned Splunk, I designed a replacement that went beyond just logging \u2014 suppliers can now query their own API data. Three-tier architecture: reusable library for interception, Kafka for durability, GCS with Parquet for cheap queryable storage. 2 million events daily, zero latency impact, 99% cost reduction.`,
      '90s': `My biggest project at Walmart was designing an audit logging system from scratch. When Splunk was being decommissioned, I saw an opportunity to build something better \u2014 not just replace logging, but give our external suppliers like Pepsi and Coca-Cola direct access to their API interaction data.\n\nI designed a three-tier architecture: a reusable Spring Boot library that intercepts HTTP requests asynchronously, a Kafka publisher for durability with Avro serialization, and a Kafka Connect sink that writes to GCS in Parquet format. BigQuery sits on top \u2014 suppliers can run SQL queries on their own data.\n\nThe system handles 2 million events daily with less than 5ms P99 latency impact. We went from Splunk costing $50K/month to about $500/month. And three other teams adopted the library within a month.`,
      '2min': `At Walmart Luminate, we serve external suppliers like Pepsi, Coca-Cola, and Unilever through APIs. Two things happened: Splunk was being decommissioned company-wide, and suppliers asked for visibility into their API interactions.\n\nSo I needed to build a system that would: replace Splunk for internal debugging, give suppliers query access, and do this without impacting API latency \u2014 they expect sub-200ms responses.\n\nI designed a three-tier solution:\n\n**First**, a reusable Spring Boot JAR that any service can import. It has a servlet filter that intercepts requests, caches the body using ContentCachingWrapper, and after the response, sends the audit payload asynchronously. Fire-and-forget \u2014 no latency impact.\n\n**Second**, a Kafka publisher service that serializes to Avro (70% smaller than JSON) and publishes to a multi-region Kafka cluster.\n\n**Third**, a Kafka Connect sink with custom SMT filters that route US, Canada, and Mexico records to separate GCS buckets in Parquet format. BigQuery external tables sit on top \u2014 that\u2019s what suppliers query.\n\nResult: 2 million events daily, P99 under 5ms, suppliers self-serve debugging, 99% cost savings.`,
    },
    // Section metadata — maps H2 heading titles to icons and quick-mode flags
    sectionMeta: {
      'Your Pitches':                    { icon: 'Mic', quickMode: true },
      'Key Numbers':                     { icon: 'Hash', quickMode: true },
      'The Pyramid Method':              { icon: 'Triangle', quickMode: true },
      'Architecture Overview':           { icon: 'Layers', quickMode: false },
      'Tier 1: Common Library':          { icon: 'Package', quickMode: false },
      'Tier 2: Kafka Publisher':         { icon: 'Send', quickMode: false },
      'Tier 3: GCS Sink':               { icon: 'Database', quickMode: false },
      'Multi-Region Architecture':       { icon: 'Globe', quickMode: false },
      'Top 10 Technical Decisions':      { icon: 'GitBranch', quickMode: true },
      'The Debugging Story (5-Day Timeline)': { icon: 'Bug', quickMode: true },
      'All Production Issues':           { icon: 'AlertTriangle', quickMode: false },
      'Behavioral Stories (STAR Format)': { icon: 'Heart', quickMode: true },
      'Interview Q&A Bank':              { icon: 'MessageCircle', quickMode: true },
      'What-If Scenarios':               { icon: 'HelpCircle', quickMode: true },
      'How to Speak':                    { icon: 'Volume2', quickMode: true },
      'PR Reference':                    { icon: 'GitPullRequest', quickMode: false },
    },
  },
  {
    slug: 'spring-boot-3-migration',
    title: 'Spring Boot 3 & Java 17 Migration',
    subtitle: 'SB 2.7\u21923.2, Java 11\u219217, 158 files, zero downtime',
    company: 'Walmart Luminate',
    role: 'Led the migration',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Files changed', value: '158' },
      { label: 'javax\u2192jakarta', value: '74 files' },
      { label: 'Test files', value: '42' },
      { label: 'Customer issues', value: '0' },
      { label: 'Duration', value: '4 weeks' },
      { label: 'Deployment', value: 'Canary' },
    ],
    pitches: {
      '30s': `I led the migration of cp-nrti-apis from Spring Boot 2.7 to 3.2 and Java 11 to 17. Main challenges: javax\u2192jakarta across 74 files, RestTemplate to WebClient, Hibernate 6 compatibility. Zero-downtime deployment using Flagger canary releases \u2014 10% traffic initially, gradually to 100% over 24 hours with automatic rollback.`,
      '60s': `I led the migration of our main supplier-facing API from Spring Boot 2.7 to 3.2, along with Java 11 to 17. This was driven by security \u2014 Snyk was flagging CVEs we couldn't patch without upgrading, and we'd fail audit in 3 months.\n\nThree major challenges: the javax-to-jakarta namespace change across 74 files, migrating RestTemplate to WebClient, and adapting to Hibernate 6's stricter handling of PostgreSQL enums.\n\nThe most strategic decision was using WebClient with .block() instead of going fully reactive \u2014 scope control over perfection. 158 files changed, zero customer-impacting issues. Deployed using Flagger canary releases \u2014 10% traffic initially, gradually to 100% over 24 hours with automatic rollback.`,
    },
    sectionMeta: {
      'Your Pitches':                       { icon: 'Mic', quickMode: true },
      'Key Numbers':                        { icon: 'Hash', quickMode: true },
      'Architecture Overview':              { icon: 'Layers', quickMode: false },
      'The .block() Decision':              { icon: 'Zap', quickMode: true },
      'javax -> jakarta Namespace Change':  { icon: 'FileText', quickMode: false },
      'RestTemplate -> WebClient Migration': { icon: 'FileText', quickMode: false },
      'Hibernate 6 Compatibility':          { icon: 'Database', quickMode: false },
      'Kafka: ListenableFuture -> CompletableFuture': { icon: 'Send', quickMode: false },
      'Spring Security 6':                  { icon: 'FileText', quickMode: false },
      'Java 17: .toList() Stream Improvement': { icon: 'FileText', quickMode: false },
      'Exception Handler Updates':          { icon: 'FileText', quickMode: false },
      'Deployment Strategy':                { icon: 'Globe', quickMode: true },
      'Technical Decisions':                { icon: 'GitBranch', quickMode: true },
      'Post-Migration Issues':              { icon: 'AlertTriangle', quickMode: false },
      'Behavioral Stories (STAR)':          { icon: 'Heart', quickMode: true },
      'Interview Q&A Bank':                 { icon: 'MessageCircle', quickMode: true },
      'What-If Scenarios':                  { icon: 'HelpCircle', quickMode: true },
      'How to Speak':                       { icon: 'Volume2', quickMode: true },
      'All Changes Summary':                { icon: 'FileText', quickMode: false },
      'PR Reference':                       { icon: 'GitPullRequest', quickMode: false },
      'Interview Sound Bites':              { icon: 'Mic', quickMode: true },
    },
  },
  {
    slug: 'dsd-notification-system',
    title: 'DSD Notification System',
    subtitle: 'Real-time push notifications for 1,200+ store associates',
    company: 'Walmart Luminate',
    role: 'Built notification pipeline',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Associates', value: '1,200+' },
      { label: 'Stores', value: '300+' },
      { label: 'Improvement', value: '35%' },
      { label: 'Events', value: '5 types' },
      { label: 'Notify on', value: '2 only' },
      { label: 'Latency', value: '<5s' },
    ],
    pitches: {
      '30s': `I built real-time push notifications for Direct Store Delivery shipments. When a supplier like Pepsi delivers goods to a Walmart store, our system captures the shipment event, builds a Kafka message, and sends a SUMO push notification to the store associate's device. 1,200+ associates across 300+ stores, 35% improvement in replenishment timing.`,
    },
    sectionMeta: {
      'Your Pitch':               { icon: 'Mic', quickMode: true },
      'Key Numbers':              { icon: 'Hash', quickMode: true },
      'Architecture':             { icon: 'Layers', quickMode: false },
      'Technical Implementation': { icon: 'FileText', quickMode: false },
      'Technical Decisions':      { icon: 'GitBranch', quickMode: true },
      'Interview Q&A':            { icon: 'MessageCircle', quickMode: true },
      'Behavioral Story':         { icon: 'Heart', quickMode: true },
      'How to Speak':             { icon: 'Volume2', quickMode: true },
      'PR Reference':             { icon: 'GitPullRequest', quickMode: false },
    },
  },
  {
    slug: 'openapi-dc-inventory',
    title: 'OpenAPI Design-First & DC Inventory API',
    subtitle: 'Spec to production: 8,000+ lines across 8 PRs',
    company: 'Walmart Luminate',
    role: 'Designed & built end-to-end',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'API spec', value: '+898 lines' },
      { label: 'Implementation', value: '+3,059' },
      { label: 'Error refactor', value: '+1,903' },
      { label: 'Tests', value: '+1,724' },
      { label: 'Total code', value: '8K+ lines' },
      { label: 'Integration', value: '-30%' },
    ],
    pitches: {
      '60s': `I designed and built the DC Inventory Search API end-to-end. I started design-first \u2014 wrote 898 lines of OpenAPI spec with schemas and examples before any code. This let the consumer team start integration immediately while I built the implementation.\n\nThe API processes requests through a 3-stage pipeline: GTIN conversion via UberKey, supplier authorization validation, and Enterprise Inventory data fetch. Each stage tracks errors separately \u2014 so for bulk requests of 100 items, the consumer knows exactly which items failed at which stage.\n\nI used a factory pattern for multi-site support \u2014 US, Canada, Mexico. Adding a new country is one class. The error handling refactor alone was 1,903 lines. Total: over 8,000 lines from spec to container tests.`,
    },
    sectionMeta: {
      'Your Pitch':                    { icon: 'Mic', quickMode: true },
      'Key Numbers':                   { icon: 'Hash', quickMode: true },
      'Architecture':                  { icon: 'Layers', quickMode: false },
      'OpenAPI Design-First':          { icon: 'FileText', quickMode: false },
      'DC Inventory Implementation':   { icon: 'FileText', quickMode: false },
      'Error Handling (RequestProcessor)': { icon: 'AlertTriangle', quickMode: false },
      'Technical Decisions':           { icon: 'GitBranch', quickMode: true },
      'The Debugging Story':           { icon: 'Bug', quickMode: true },
      'Behavioral Stories':            { icon: 'Heart', quickMode: true },
      'Interview Q&A':                 { icon: 'MessageCircle', quickMode: true },
      'What-If Scenarios':             { icon: 'HelpCircle', quickMode: true },
      'How to Speak':                  { icon: 'Volume2', quickMode: true },
      'PR Reference':                  { icon: 'GitPullRequest', quickMode: false },
    },
  },
  {
    slug: 'common-library-jar',
    title: 'Common Library JAR',
    subtitle: 'Reusable Spring Boot library for cross-cutting concerns',
    company: 'Walmart Luminate',
    role: 'Designed & maintained',
    masterFile: 'README.md',
    numbers: [],
    pitches: {},
    sectionMeta: {},
  },
  {
    slug: 'transaction-event-history',
    title: 'Transaction Event History',
    subtitle: 'Event sourcing for inventory transaction tracking',
    company: 'Walmart Luminate',
    role: 'Built event pipeline',
    masterFile: 'README.md',
    numbers: [],
    pitches: {},
    sectionMeta: {},
  },
  {
    slug: 'observability',
    title: 'Observability',
    subtitle: 'Monitoring, alerting, and distributed tracing infrastructure',
    company: 'Walmart Luminate',
    role: 'Set up observability stack',
    masterFile: 'README.md',
    numbers: [],
    pitches: {},
    sectionMeta: {},
  },
  // ============ GCC PROJECTS ============
  {
    slug: 'gcc-beat-scraping',
    title: 'Beat \u2014 Social Media Scraping Engine',
    subtitle: '10M+ daily data points, 73 flows, 150+ concurrent workers',
    company: 'Good Creator Co.',
    role: 'Built core data engine',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Data points/day', value: '10M+' },
      { label: 'Scraping flows', value: '73+' },
      { label: 'Workers', value: '150+' },
      { label: 'Images/day', value: '8M' },
      { label: 'API integrations', value: '15+' },
      { label: 'Python LOC', value: '15K+' },
    ],
    pitches: {
      '30s': `At Good Creator Co., I built Beat \u2014 the core data collection engine for our influencer marketing SaaS. It aggregates data from 15+ social media APIs using 150+ concurrent workers across 73 scraping flows. I designed a 3-level stacked rate limiting system, credential rotation with TTL backoff, and a SQL task queue with FOR UPDATE SKIP LOCKED. 10 million data points daily, 8 million images via S3 pipeline.`,
    },
    sectionMeta: {
      'Resume Bullets Covered':     { icon: 'FileText', quickMode: false },
      '1. Pitches':                 { icon: 'Mic', quickMode: true },
      '2. Key Numbers':             { icon: 'Hash', quickMode: true },
      '3. Architecture':            { icon: 'Layers', quickMode: false },
      '4. Technical Implementation': { icon: 'FileText', quickMode: false },
      '5. Technical Decisions -- "Why THIS and Not THAT?"': { icon: 'GitBranch', quickMode: true },
      '6. Interview Q&A':           { icon: 'MessageCircle', quickMode: true },
      '7. Behavioral Stories (STAR Format)': { icon: 'Heart', quickMode: true },
      '8. What-If Scenarios':       { icon: 'HelpCircle', quickMode: true },
      '9. How to Speak':            { icon: 'Volume2', quickMode: true },
    },
  },
  {
    slug: 'gcc-event-grpc',
    title: 'Event-gRPC \u2014 Real-Time Event Ingestion',
    subtitle: 'Go + gRPC + RabbitMQ + ClickHouse, 10M+ events/day',
    company: 'Good Creator Co.',
    role: 'Built event pipeline',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Events/day', value: '10M+' },
      { label: 'Event types', value: '60+' },
      { label: 'RabbitMQ queues', value: '26' },
      { label: 'Workers', value: '90+' },
      { label: 'ClickHouse tables', value: '18+' },
      { label: 'Go LOC', value: '10K+' },
    ],
    pitches: {
      '30s': `I built Event-gRPC, the real-time event ingestion backbone for GCC\u2019s analytics platform. Go service handling 10M+ daily data points across 60+ event types. Events arrive via gRPC, fan out through 26 RabbitMQ queues to 90+ consumer workers. High-volume streams use a buffered sinker pattern flushing batches to ClickHouse \u2014 2.5x faster retrieval over PostgreSQL.`,
    },
    sectionMeta: {
      'Table of Contents':          { icon: 'FileText', quickMode: false },
      '1. Elevator Pitches':        { icon: 'Mic', quickMode: true },
      '2. Key Numbers':             { icon: 'Hash', quickMode: true },
      '3. Architecture':            { icon: 'Layers', quickMode: false },
      '4. Technical Implementation': { icon: 'FileText', quickMode: false },
      '5. Technical Decisions':     { icon: 'GitBranch', quickMode: true },
      '6. Interview Q&A':           { icon: 'MessageCircle', quickMode: true },
      '7. Behavioral Stories (STAR)': { icon: 'Heart', quickMode: true },
      '8. What-If Scenarios':       { icon: 'HelpCircle', quickMode: true },
      '9. How to Speak About This Project': { icon: 'Volume2', quickMode: true },
    },
  },
  {
    slug: 'gcc-stir-data-platform',
    title: 'Stir \u2014 Data Platform (Airflow + dbt)',
    subtitle: '76 DAGs, 112 dbt models, 50% data latency reduction',
    company: 'Good Creator Co.',
    role: 'Built ETL platform',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Airflow DAGs', value: '76' },
      { label: 'dbt models', value: '112' },
      { label: 'Latency cut', value: '50%' },
      { label: 'Git commits', value: '1,476' },
      { label: 'Schedule range', value: '5min\u2192weekly' },
      { label: 'Python LOC', value: '17.5K+' },
    ],
    pitches: {
      '30s': `I built Stir \u2014 the data transformation platform powering GCC\u2019s analytics. 76 Airflow DAGs orchestrating 112 dbt models through a three-layer pipeline: ClickHouse transforms, S3 JSON staging, then atomic table swaps into PostgreSQL. Scheduling from every 5 minutes to weekly. Cut data latency by 50%.`,
    },
    sectionMeta: {
      'Pitches':                    { icon: 'Mic', quickMode: true },
      'Key Numbers':                { icon: 'Hash', quickMode: true },
      'Architecture':               { icon: 'Layers', quickMode: false },
      'Technical Implementation':   { icon: 'FileText', quickMode: false },
      'Technical Decisions':        { icon: 'GitBranch', quickMode: true },
      'Interview Q&A':              { icon: 'MessageCircle', quickMode: true },
      'Behavioral Stories':         { icon: 'Heart', quickMode: true },
      'What-If Scenarios':          { icon: 'HelpCircle', quickMode: true },
      'How to Speak':               { icon: 'Volume2', quickMode: true },
    },
  },
  {
    slug: 'gcc-coffee-saas-api',
    title: 'Coffee + SaaS Gateway',
    subtitle: 'Multi-tenant Go API, 50+ endpoints, 25% faster responses',
    company: 'Good Creator Co.',
    role: 'Built core backend + gateway',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Endpoints', value: '50+' },
      { label: 'Modules', value: '12' },
      { label: 'Services proxied', value: '13' },
      { label: 'Response time', value: '-25%' },
      { label: 'Cost savings', value: '-30%' },
      { label: 'Engagement', value: '+10%' },
    ],
    pitches: {
      '30s': `I built Coffee \u2014 the core backend for GCC\u2019s SaaS platform. Multi-tenant Go REST API with 50+ endpoints across 12 business modules using Go generics for type-safe CRUD. In front sits the SaaS Gateway I also built \u2014 JWT + Redis auth, two-layer cache (Ristretto + Redis), proxying all 13 microservices. API response times improved 25%, operational costs down 30%.`,
    },
    sectionMeta: {
      'Pitches':                    { icon: 'Mic', quickMode: true },
      'Key Numbers':                { icon: 'Hash', quickMode: true },
      'Architecture':               { icon: 'Layers', quickMode: false },
      'Technical Implementation':   { icon: 'FileText', quickMode: false },
      'Technical Decisions':        { icon: 'GitBranch', quickMode: true },
      'Interview Q&A':              { icon: 'MessageCircle', quickMode: true },
      'Behavioral Stories':         { icon: 'Heart', quickMode: true },
      'What-If Scenarios':          { icon: 'HelpCircle', quickMode: true },
      'How to Speak':               { icon: 'Volume2', quickMode: true },
    },
  },
  {
    slug: 'gcc-fake-follower-ml',
    title: 'Fake Follower Detection (ML)',
    subtitle: '5-feature ensemble, 10 Indic scripts, AWS Lambda pipeline',
    company: 'Good Creator Co.',
    role: 'Built ML system end-to-end',
    masterFile: '00-INTERVIEW-MASTER.md',
    numbers: [
      { label: 'Ensemble features', value: '5' },
      { label: 'Indic scripts', value: '10' },
      { label: 'Name DB', value: '35K+' },
      { label: 'Speed gain', value: '50%' },
      { label: 'AWS services', value: '5' },
      { label: 'Python LOC', value: '955+' },
    ],
    pitches: {
      '30s': `I built an ML-powered fake follower detection system for Instagram. The challenge: Indian users write names in 10 different scripts. I built a 5-feature ensemble \u2014 HMM-based transliteration, weighted fuzzy matching with RapidFuzz, 35K-name Indian name database, bot pattern detection. Runs on serverless AWS Lambda + SQS + Kinesis, processing 50% faster than the previous approach.`,
    },
    sectionMeta: {
      'Pitches':                    { icon: 'Mic', quickMode: true },
      'Key Numbers':                { icon: 'Hash', quickMode: true },
      'Architecture':               { icon: 'Layers', quickMode: false },
      'Technical Implementation':   { icon: 'FileText', quickMode: false },
      'Technical Decisions':        { icon: 'GitBranch', quickMode: true },
      'Interview Q&A':              { icon: 'MessageCircle', quickMode: true },
      'Behavioral Stories':         { icon: 'Heart', quickMode: true },
      'What-If Scenarios':          { icon: 'HelpCircle', quickMode: true },
      'How to Speak':               { icon: 'Volume2', quickMode: true },
    },
  },
]

export function getProject(slug) {
  return interviewProjects.find(p => p.slug === slug)
}

// Split master document content by H2 headings into sections
export function splitBySections(content) {
  if (!content) return []
  const lines = content.split('\n')
  const sections = []
  let current = null

  for (const line of lines) {
    const h2Match = line.match(/^## (.+)$/)
    if (h2Match) {
      if (current) sections.push(current)
      current = { title: h2Match[1], content: '' }
    } else if (current) {
      current.content += line + '\n'
    }
  }
  if (current) sections.push(current)

  return sections.map((s, i) => ({
    ...s,
    id: s.title.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-|-$/g, ''),
    index: i + 1,
    content: s.content.trim(),
  }))
}
